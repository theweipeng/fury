// Code generated by forygen. DO NOT EDIT.
// source: structs.go
// generated at: 2025-12-07T02:20:01+08:00

package fory

import (
	"fmt"
	"github.com/apache/fory/go/fory"
	"reflect"
)

func init() {
	fory.RegisterSerializerFactory((*DynamicSliceDemo)(nil), NewSerializerFor_DynamicSliceDemo)
	fory.RegisterSerializerFactory((*MapDemo)(nil), NewSerializerFor_MapDemo)
	fory.RegisterSerializerFactory((*SliceDemo)(nil), NewSerializerFor_SliceDemo)
	fory.RegisterSerializerFactory((*ValidationDemo)(nil), NewSerializerFor_ValidationDemo)
}

type DynamicSliceDemo_ForyGenSerializer struct{}

func NewSerializerFor_DynamicSliceDemo() fory.Serializer {
	return DynamicSliceDemo_ForyGenSerializer{}
}

func (DynamicSliceDemo_ForyGenSerializer) TypeId() fory.TypeId {
	return fory.NAMED_STRUCT
}

func (DynamicSliceDemo_ForyGenSerializer) NeedToWriteRef() bool {
	return true
}

// WriteTyped provides strongly-typed serialization with no reflection overhead
func (g DynamicSliceDemo_ForyGenSerializer) WriteTyped(ctx *fory.WriteContext, v *DynamicSliceDemo) error {
	buf := ctx.Buffer()
	// Write precomputed struct hash for compatibility checking
	buf.WriteInt32(659991945) // hash of DynamicSliceDemo structure

	// Write fields in sorted order
	// Field: DynamicSlice ([]interface{})
	// Dynamic slice []interface{} handling - manual serialization
	if v.DynamicSlice == nil {
		buf.WriteInt8(-3) // null value flag
	} else {
		// Write reference flag for the slice itself
		buf.WriteInt8(0) // RefValueFlag
		// Write slice length
		buf.WriteVarUint32(uint32(len(v.DynamicSlice)))
		// Write collection flags for dynamic slice []interface{}
		// Only CollectionTrackingRef is set (no declared type, may have different types)
		buf.WriteInt8(1) // CollectionTrackingRef only
		// Write each element using WriteValue
		for _, elem := range v.DynamicSlice {
			ctx.WriteValue(reflect.ValueOf(elem))
		}
	}
	return nil
}

// ReadTyped provides strongly-typed deserialization with no reflection overhead
func (g DynamicSliceDemo_ForyGenSerializer) ReadTyped(ctx *fory.ReadContext, v *DynamicSliceDemo) error {
	buf := ctx.Buffer()
	// Read and verify struct hash
	if got := buf.ReadInt32(); got != 659991945 {
		return fmt.Errorf("struct hash mismatch for DynamicSliceDemo: expected 659991945, got %d", got)
	}

	// Read fields in same order as write
	// Field: DynamicSlice ([]interface{})
	// Dynamic slice []interface{} handling - manual deserialization
	if flag := buf.ReadInt8(); flag == -3 {
		v.DynamicSlice = nil // null slice
	} else if flag == 0 {
		// Read slice length
		sliceLen := buf.ReadVarUint32()
		// Read collection flags (ignore for now)
		_ = buf.ReadInt8()
		// Create slice with proper capacity
		v.DynamicSlice = make([]interface{}, sliceLen)
		// Read each element using ReadValue
		for i := range v.DynamicSlice {
			ctx.ReadValue(reflect.ValueOf(&v.DynamicSlice[i]).Elem())
		}
	} else {
		return fmt.Errorf("expected RefValueFlag or NullFlag for dynamic slice field DynamicSlice, got %d", flag)
	}
	return nil
}

// Write provides reflect.Value interface compatibility (implements fory.Serializer)
func (g DynamicSliceDemo_ForyGenSerializer) Write(ctx *fory.WriteContext, value reflect.Value) error {
	// Convert reflect.Value to concrete type and delegate to typed method
	var v *DynamicSliceDemo
	if value.Kind() == reflect.Ptr {
		v = value.Interface().(*DynamicSliceDemo)
	} else {
		// Create a copy to get a pointer
		temp := value.Interface().(DynamicSliceDemo)
		v = &temp
	}
	// Delegate to strongly-typed method for maximum performance
	return g.WriteTyped(ctx, v)
}

// Read provides reflect.Value interface compatibility (implements fory.Serializer)
func (g DynamicSliceDemo_ForyGenSerializer) Read(ctx *fory.ReadContext, type_ reflect.Type, value reflect.Value) error {
	// Convert reflect.Value to concrete type and delegate to typed method
	var v *DynamicSliceDemo
	if value.Kind() == reflect.Ptr {
		if value.IsNil() {
			// For pointer types, allocate using type_.Elem()
			value.Set(reflect.New(type_.Elem()))
		}
		v = value.Interface().(*DynamicSliceDemo)
	} else {
		// value must be addressable for read
		v = value.Addr().Interface().(*DynamicSliceDemo)
	}
	// Delegate to strongly-typed method for maximum performance
	return g.ReadTyped(ctx, v)
}

type MapDemo_ForyGenSerializer struct{}

func NewSerializerFor_MapDemo() fory.Serializer {
	return MapDemo_ForyGenSerializer{}
}

func (MapDemo_ForyGenSerializer) TypeId() fory.TypeId {
	return fory.NAMED_STRUCT
}

func (MapDemo_ForyGenSerializer) NeedToWriteRef() bool {
	return true
}

// WriteTyped provides strongly-typed serialization with no reflection overhead
func (g MapDemo_ForyGenSerializer) WriteTyped(ctx *fory.WriteContext, v *MapDemo) error {
	buf := ctx.Buffer()
	// Write precomputed struct hash for compatibility checking
	buf.WriteInt32(-1565547955) // hash of MapDemo structure

	// Write fields in sorted order
	// Field: IntMap (map[int]int)
	buf.WriteInt8(0) // RefValueFlag for map
	{
		mapLen := 0
		if v.IntMap != nil {
			mapLen = len(v.IntMap)
		}
		buf.WriteVarUint32(uint32(mapLen))
		if mapLen > 0 {
			// Calculate KV header flags
			kvHeader := uint8(0)
			isRefTracking := ctx.TrackRef()
			_ = isRefTracking // Mark as used to avoid warning
			chunkSize := 0
			_ = buf.WriterIndex()         // chunkHeaderOffset
			buf.WriteInt8(int8(kvHeader)) // KV header
			chunkSizeOffset := buf.WriterIndex()
			buf.WriteInt8(0) // placeholder for chunk size
			for mapKey, mapValue := range v.IntMap {
				buf.WriteInt64(int64(mapKey))
				buf.WriteInt64(int64(mapValue))
				chunkSize++
				if chunkSize >= 255 {
					// Write chunk size and start new chunk
					buf.PutUint8(chunkSizeOffset, uint8(chunkSize))
					if len(v.IntMap) > chunkSize {
						chunkSize = 0
						_ = buf.WriterIndex()         // chunkHeaderOffset
						buf.WriteInt8(int8(kvHeader)) // KV header
						chunkSizeOffset = buf.WriterIndex()
						buf.WriteInt8(0) // placeholder for chunk size
					}
				}
			}
			if chunkSize > 0 {
				buf.PutUint8(chunkSizeOffset, uint8(chunkSize))
			}
		}
	}
	// Field: MixedMap (map[string]int)
	buf.WriteInt8(0) // RefValueFlag for map
	{
		mapLen := 0
		if v.MixedMap != nil {
			mapLen = len(v.MixedMap)
		}
		buf.WriteVarUint32(uint32(mapLen))
		if mapLen > 0 {
			// Calculate KV header flags
			kvHeader := uint8(0)
			isRefTracking := ctx.TrackRef()
			_ = isRefTracking // Mark as used to avoid warning
			if isRefTracking {
				kvHeader |= 0x1 // track key ref
			}
			chunkSize := 0
			_ = buf.WriterIndex()         // chunkHeaderOffset
			buf.WriteInt8(int8(kvHeader)) // KV header
			chunkSizeOffset := buf.WriterIndex()
			buf.WriteInt8(0) // placeholder for chunk size
			for mapKey, mapValue := range v.MixedMap {
				fory.WriteString(buf, mapKey)
				buf.WriteInt64(int64(mapValue))
				chunkSize++
				if chunkSize >= 255 {
					// Write chunk size and start new chunk
					buf.PutUint8(chunkSizeOffset, uint8(chunkSize))
					if len(v.MixedMap) > chunkSize {
						chunkSize = 0
						_ = buf.WriterIndex()         // chunkHeaderOffset
						buf.WriteInt8(int8(kvHeader)) // KV header
						chunkSizeOffset = buf.WriterIndex()
						buf.WriteInt8(0) // placeholder for chunk size
					}
				}
			}
			if chunkSize > 0 {
				buf.PutUint8(chunkSizeOffset, uint8(chunkSize))
			}
		}
	}
	// Field: StringMap (map[string]string)
	buf.WriteInt8(0) // RefValueFlag for map
	{
		mapLen := 0
		if v.StringMap != nil {
			mapLen = len(v.StringMap)
		}
		buf.WriteVarUint32(uint32(mapLen))
		if mapLen > 0 {
			// Calculate KV header flags
			kvHeader := uint8(0)
			isRefTracking := ctx.TrackRef()
			_ = isRefTracking // Mark as used to avoid warning
			if isRefTracking {
				kvHeader |= 0x1 // track key ref
			}
			if isRefTracking {
				kvHeader |= 0x8 // track value ref
			}
			chunkSize := 0
			_ = buf.WriterIndex()         // chunkHeaderOffset
			buf.WriteInt8(int8(kvHeader)) // KV header
			chunkSizeOffset := buf.WriterIndex()
			buf.WriteInt8(0) // placeholder for chunk size
			for mapKey, mapValue := range v.StringMap {
				fory.WriteString(buf, mapKey)
				fory.WriteString(buf, mapValue)
				chunkSize++
				if chunkSize >= 255 {
					// Write chunk size and start new chunk
					buf.PutUint8(chunkSizeOffset, uint8(chunkSize))
					if len(v.StringMap) > chunkSize {
						chunkSize = 0
						_ = buf.WriterIndex()         // chunkHeaderOffset
						buf.WriteInt8(int8(kvHeader)) // KV header
						chunkSizeOffset = buf.WriterIndex()
						buf.WriteInt8(0) // placeholder for chunk size
					}
				}
			}
			if chunkSize > 0 {
				buf.PutUint8(chunkSizeOffset, uint8(chunkSize))
			}
		}
	}
	return nil
}

// ReadTyped provides strongly-typed deserialization with no reflection overhead
func (g MapDemo_ForyGenSerializer) ReadTyped(ctx *fory.ReadContext, v *MapDemo) error {
	buf := ctx.Buffer()
	// Read and verify struct hash
	if got := buf.ReadInt32(); got != -1565547955 {
		return fmt.Errorf("struct hash mismatch for MapDemo: expected -1565547955, got %d", got)
	}

	// Read fields in same order as write
	// Field: IntMap (map[int]int)
	if flag := buf.ReadInt8(); flag != 0 {
		return fmt.Errorf("expected RefValueFlag for map field, got %d", flag)
	}
	{
		mapLen := int(buf.ReadVarUint32())
		if mapLen == 0 {
			v.IntMap = make(map[int]int)
		} else {
			v.IntMap = make(map[int]int, mapLen)
			mapSize := mapLen
			for mapSize > 0 {
				// Read KV header
				kvHeader := buf.ReadUint8()
				chunkSize := int(buf.ReadUint8())
				trackKeyRef := (kvHeader & 0x1) != 0
				keyNotDeclared := (kvHeader & 0x4) != 0
				trackValueRef := (kvHeader & 0x8) != 0
				valueNotDeclared := (kvHeader & 0x20) != 0
				_ = trackKeyRef
				_ = keyNotDeclared
				_ = trackValueRef
				_ = valueNotDeclared
				for i := 0; i < chunkSize; i++ {
					var mapKey int
					mapKey = int(buf.ReadInt64())
					var mapValue int
					mapValue = int(buf.ReadInt64())
					v.IntMap[mapKey] = mapValue
				}
				mapSize -= chunkSize
			}
		}
	}
	// Field: MixedMap (map[string]int)
	if flag := buf.ReadInt8(); flag != 0 {
		return fmt.Errorf("expected RefValueFlag for map field, got %d", flag)
	}
	{
		mapLen := int(buf.ReadVarUint32())
		if mapLen == 0 {
			v.MixedMap = make(map[string]int)
		} else {
			v.MixedMap = make(map[string]int, mapLen)
			mapSize := mapLen
			for mapSize > 0 {
				// Read KV header
				kvHeader := buf.ReadUint8()
				chunkSize := int(buf.ReadUint8())
				trackKeyRef := (kvHeader & 0x1) != 0
				keyNotDeclared := (kvHeader & 0x4) != 0
				trackValueRef := (kvHeader & 0x8) != 0
				valueNotDeclared := (kvHeader & 0x20) != 0
				_ = trackKeyRef
				_ = keyNotDeclared
				_ = trackValueRef
				_ = valueNotDeclared
				for i := 0; i < chunkSize; i++ {
					var mapKey string
					mapKey = fory.ReadString(buf)
					var mapValue int
					mapValue = int(buf.ReadInt64())
					v.MixedMap[mapKey] = mapValue
				}
				mapSize -= chunkSize
			}
		}
	}
	// Field: StringMap (map[string]string)
	if flag := buf.ReadInt8(); flag != 0 {
		return fmt.Errorf("expected RefValueFlag for map field, got %d", flag)
	}
	{
		mapLen := int(buf.ReadVarUint32())
		if mapLen == 0 {
			v.StringMap = make(map[string]string)
		} else {
			v.StringMap = make(map[string]string, mapLen)
			mapSize := mapLen
			for mapSize > 0 {
				// Read KV header
				kvHeader := buf.ReadUint8()
				chunkSize := int(buf.ReadUint8())
				trackKeyRef := (kvHeader & 0x1) != 0
				keyNotDeclared := (kvHeader & 0x4) != 0
				trackValueRef := (kvHeader & 0x8) != 0
				valueNotDeclared := (kvHeader & 0x20) != 0
				_ = trackKeyRef
				_ = keyNotDeclared
				_ = trackValueRef
				_ = valueNotDeclared
				for i := 0; i < chunkSize; i++ {
					var mapKey string
					mapKey = fory.ReadString(buf)
					var mapValue string
					mapValue = fory.ReadString(buf)
					v.StringMap[mapKey] = mapValue
				}
				mapSize -= chunkSize
			}
		}
	}
	return nil
}

// Write provides reflect.Value interface compatibility (implements fory.Serializer)
func (g MapDemo_ForyGenSerializer) Write(ctx *fory.WriteContext, value reflect.Value) error {
	// Convert reflect.Value to concrete type and delegate to typed method
	var v *MapDemo
	if value.Kind() == reflect.Ptr {
		v = value.Interface().(*MapDemo)
	} else {
		// Create a copy to get a pointer
		temp := value.Interface().(MapDemo)
		v = &temp
	}
	// Delegate to strongly-typed method for maximum performance
	return g.WriteTyped(ctx, v)
}

// Read provides reflect.Value interface compatibility (implements fory.Serializer)
func (g MapDemo_ForyGenSerializer) Read(ctx *fory.ReadContext, type_ reflect.Type, value reflect.Value) error {
	// Convert reflect.Value to concrete type and delegate to typed method
	var v *MapDemo
	if value.Kind() == reflect.Ptr {
		if value.IsNil() {
			// For pointer types, allocate using type_.Elem()
			value.Set(reflect.New(type_.Elem()))
		}
		v = value.Interface().(*MapDemo)
	} else {
		// value must be addressable for read
		v = value.Addr().Interface().(*MapDemo)
	}
	// Delegate to strongly-typed method for maximum performance
	return g.ReadTyped(ctx, v)
}

type SliceDemo_ForyGenSerializer struct{}

func NewSerializerFor_SliceDemo() fory.Serializer {
	return SliceDemo_ForyGenSerializer{}
}

func (SliceDemo_ForyGenSerializer) TypeId() fory.TypeId {
	return fory.NAMED_STRUCT
}

func (SliceDemo_ForyGenSerializer) NeedToWriteRef() bool {
	return true
}

// WriteTyped provides strongly-typed serialization with no reflection overhead
func (g SliceDemo_ForyGenSerializer) WriteTyped(ctx *fory.WriteContext, v *SliceDemo) error {
	buf := ctx.Buffer()
	// Write precomputed struct hash for compatibility checking
	buf.WriteInt32(-1393614469) // hash of SliceDemo structure

	// Write fields in sorted order
	// Field: BoolSlice ([]bool)
	buf.WriteInt8(0) // RefValueFlag for slice
	{
		sliceLen := 0
		if v.BoolSlice != nil {
			sliceLen = len(v.BoolSlice)
		}
		buf.WriteVarUint32(uint32(sliceLen))
		if sliceLen > 0 {
			collectFlag := 8 // CollectionIsSameType only
			buf.WriteInt8(int8(collectFlag))
			buf.WriteVarInt32(1) // BOOL
			for _, elem := range v.BoolSlice {
				buf.WriteBool(elem)
			}
		}
	}
	// Field: FloatSlice ([]float64)
	buf.WriteInt8(0) // RefValueFlag for slice
	{
		sliceLen := 0
		if v.FloatSlice != nil {
			sliceLen = len(v.FloatSlice)
		}
		buf.WriteVarUint32(uint32(sliceLen))
		if sliceLen > 0 {
			collectFlag := 8 // CollectionIsSameType only
			buf.WriteInt8(int8(collectFlag))
			buf.WriteVarInt32(11) // DOUBLE
			for _, elem := range v.FloatSlice {
				buf.WriteFloat64(elem)
			}
		}
	}
	// Field: IntSlice ([]int32)
	buf.WriteInt8(0) // RefValueFlag for slice
	{
		sliceLen := 0
		if v.IntSlice != nil {
			sliceLen = len(v.IntSlice)
		}
		buf.WriteVarUint32(uint32(sliceLen))
		if sliceLen > 0 {
			collectFlag := 8 // CollectionIsSameType only
			buf.WriteInt8(int8(collectFlag))
			buf.WriteVarInt32(4) // INT32
			for _, elem := range v.IntSlice {
				buf.WriteVarint32(elem)
			}
		}
	}
	// Field: StringSlice ([]string)
	buf.WriteInt8(0) // RefValueFlag for slice
	{
		sliceLen := 0
		if v.StringSlice != nil {
			sliceLen = len(v.StringSlice)
		}
		buf.WriteVarUint32(uint32(sliceLen))
		if sliceLen > 0 {
			collectFlag := 8 // CollectionIsSameType only
			buf.WriteInt8(int8(collectFlag))
			buf.WriteVarInt32(12) // STRING
			for _, elem := range v.StringSlice {
				fory.WriteString(buf, elem)
			}
		}
	}
	return nil
}

// ReadTyped provides strongly-typed deserialization with no reflection overhead
func (g SliceDemo_ForyGenSerializer) ReadTyped(ctx *fory.ReadContext, v *SliceDemo) error {
	buf := ctx.Buffer()
	// Read and verify struct hash
	if got := buf.ReadInt32(); got != -1393614469 {
		return fmt.Errorf("struct hash mismatch for SliceDemo: expected -1393614469, got %d", got)
	}

	// Read fields in same order as write
	// Field: BoolSlice ([]bool)
	if flag := buf.ReadInt8(); flag != 0 {
		return fmt.Errorf("expected RefValueFlag for slice field, got %d", flag)
	}
	{
		sliceLen := int(buf.ReadVarUint32())
		if sliceLen == 0 {
			v.BoolSlice = nil
		} else {
			collectFlag := buf.ReadInt8()
			// Check if CollectionIsDeclElementType is set (bit 2, value 4)
			hasDeclType := (collectFlag & 4) != 0
			v.BoolSlice = make([]bool, sliceLen)
			if hasDeclType {
				// Elements are written directly without flags/type IDs
				for i := 0; i < sliceLen; i++ {
					v.BoolSlice[i] = buf.ReadBool()
				}
			} else {
				// Need to read type ID once if CollectionIsSameType is set
				if (collectFlag & 8) != 0 {
					// Read element type ID once for all elements
					_ = buf.ReadVarInt32()
				}
				for i := 0; i < sliceLen; i++ {
					v.BoolSlice[i] = buf.ReadBool()
				}
			}
		}
	}
	// Field: FloatSlice ([]float64)
	if flag := buf.ReadInt8(); flag != 0 {
		return fmt.Errorf("expected RefValueFlag for slice field, got %d", flag)
	}
	{
		sliceLen := int(buf.ReadVarUint32())
		if sliceLen == 0 {
			v.FloatSlice = nil
		} else {
			collectFlag := buf.ReadInt8()
			// Check if CollectionIsDeclElementType is set (bit 2, value 4)
			hasDeclType := (collectFlag & 4) != 0
			v.FloatSlice = make([]float64, sliceLen)
			if hasDeclType {
				// Elements are written directly without flags/type IDs
				for i := 0; i < sliceLen; i++ {
					v.FloatSlice[i] = buf.ReadFloat64()
				}
			} else {
				// Need to read type ID once if CollectionIsSameType is set
				if (collectFlag & 8) != 0 {
					// Read element type ID once for all elements
					_ = buf.ReadVarInt32()
				}
				for i := 0; i < sliceLen; i++ {
					v.FloatSlice[i] = buf.ReadFloat64()
				}
			}
		}
	}
	// Field: IntSlice ([]int32)
	if flag := buf.ReadInt8(); flag != 0 {
		return fmt.Errorf("expected RefValueFlag for slice field, got %d", flag)
	}
	{
		sliceLen := int(buf.ReadVarUint32())
		if sliceLen == 0 {
			v.IntSlice = nil
		} else {
			collectFlag := buf.ReadInt8()
			// Check if CollectionIsDeclElementType is set (bit 2, value 4)
			hasDeclType := (collectFlag & 4) != 0
			v.IntSlice = make([]int32, sliceLen)
			if hasDeclType {
				// Elements are written directly without flags/type IDs
				for i := 0; i < sliceLen; i++ {
					v.IntSlice[i] = buf.ReadVarint32()
				}
			} else {
				// Need to read type ID once if CollectionIsSameType is set
				if (collectFlag & 8) != 0 {
					// Read element type ID once for all elements
					_ = buf.ReadVarInt32()
				}
				for i := 0; i < sliceLen; i++ {
					v.IntSlice[i] = buf.ReadVarint32()
				}
			}
		}
	}
	// Field: StringSlice ([]string)
	if flag := buf.ReadInt8(); flag != 0 {
		return fmt.Errorf("expected RefValueFlag for slice field, got %d", flag)
	}
	{
		sliceLen := int(buf.ReadVarUint32())
		if sliceLen == 0 {
			v.StringSlice = nil
		} else {
			collectFlag := buf.ReadInt8()
			// Check if CollectionIsDeclElementType is set (bit 2, value 4)
			hasDeclType := (collectFlag & 4) != 0
			v.StringSlice = make([]string, sliceLen)
			if hasDeclType {
				// Elements are written directly without flags/type IDs
				for i := 0; i < sliceLen; i++ {
					v.StringSlice[i] = fory.ReadString(buf)
				}
			} else {
				// Need to read type ID once if CollectionIsSameType is set
				if (collectFlag & 8) != 0 {
					// Read element type ID once for all elements
					_ = buf.ReadVarInt32()
				}
				for i := 0; i < sliceLen; i++ {
					v.StringSlice[i] = fory.ReadString(buf)
				}
			}
		}
	}
	return nil
}

// Write provides reflect.Value interface compatibility (implements fory.Serializer)
func (g SliceDemo_ForyGenSerializer) Write(ctx *fory.WriteContext, value reflect.Value) error {
	// Convert reflect.Value to concrete type and delegate to typed method
	var v *SliceDemo
	if value.Kind() == reflect.Ptr {
		v = value.Interface().(*SliceDemo)
	} else {
		// Create a copy to get a pointer
		temp := value.Interface().(SliceDemo)
		v = &temp
	}
	// Delegate to strongly-typed method for maximum performance
	return g.WriteTyped(ctx, v)
}

// Read provides reflect.Value interface compatibility (implements fory.Serializer)
func (g SliceDemo_ForyGenSerializer) Read(ctx *fory.ReadContext, type_ reflect.Type, value reflect.Value) error {
	// Convert reflect.Value to concrete type and delegate to typed method
	var v *SliceDemo
	if value.Kind() == reflect.Ptr {
		if value.IsNil() {
			// For pointer types, allocate using type_.Elem()
			value.Set(reflect.New(type_.Elem()))
		}
		v = value.Interface().(*SliceDemo)
	} else {
		// value must be addressable for read
		v = value.Addr().Interface().(*SliceDemo)
	}
	// Delegate to strongly-typed method for maximum performance
	return g.ReadTyped(ctx, v)
}

type ValidationDemo_ForyGenSerializer struct{}

func NewSerializerFor_ValidationDemo() fory.Serializer {
	return ValidationDemo_ForyGenSerializer{}
}

func (ValidationDemo_ForyGenSerializer) TypeId() fory.TypeId {
	return fory.NAMED_STRUCT
}

func (ValidationDemo_ForyGenSerializer) NeedToWriteRef() bool {
	return true
}

// WriteTyped provides strongly-typed serialization with no reflection overhead
func (g ValidationDemo_ForyGenSerializer) WriteTyped(ctx *fory.WriteContext, v *ValidationDemo) error {
	buf := ctx.Buffer()
	// Write precomputed struct hash for compatibility checking
	buf.WriteInt32(728169998) // hash of ValidationDemo structure

	// Write fields in sorted order
	// Field: D (float64)
	buf.WriteFloat64(v.D)
	// Field: E (bool)
	buf.WriteBool(v.E)
	// Field: C (int64)
	buf.WriteVarint64(v.C)
	// Field: A (int32)
	buf.WriteVarint32(v.A)
	// Field: B (string)
	buf.WriteInt8(-1) // NotNullValueFlag
	fory.WriteString(buf, v.B)
	return nil
}

// ReadTyped provides strongly-typed deserialization with no reflection overhead
func (g ValidationDemo_ForyGenSerializer) ReadTyped(ctx *fory.ReadContext, v *ValidationDemo) error {
	buf := ctx.Buffer()
	// Read and verify struct hash
	if got := buf.ReadInt32(); got != 728169998 {
		return fmt.Errorf("struct hash mismatch for ValidationDemo: expected 728169998, got %d", got)
	}

	// Read fields in same order as write
	// Field: D (float64)
	v.D = buf.ReadFloat64()
	// Field: E (bool)
	v.E = buf.ReadBool()
	// Field: C (int64)
	v.C = buf.ReadVarint64()
	// Field: A (int32)
	v.A = buf.ReadVarint32()
	// Field: B (string)
	if flag := buf.ReadInt8(); flag != -1 {
		return fmt.Errorf("expected NotNullValueFlag for string field B, got %d", flag)
	}
	v.B = fory.ReadString(buf)
	return nil
}

// Write provides reflect.Value interface compatibility (implements fory.Serializer)
func (g ValidationDemo_ForyGenSerializer) Write(ctx *fory.WriteContext, value reflect.Value) error {
	// Convert reflect.Value to concrete type and delegate to typed method
	var v *ValidationDemo
	if value.Kind() == reflect.Ptr {
		v = value.Interface().(*ValidationDemo)
	} else {
		// Create a copy to get a pointer
		temp := value.Interface().(ValidationDemo)
		v = &temp
	}
	// Delegate to strongly-typed method for maximum performance
	return g.WriteTyped(ctx, v)
}

// Read provides reflect.Value interface compatibility (implements fory.Serializer)
func (g ValidationDemo_ForyGenSerializer) Read(ctx *fory.ReadContext, type_ reflect.Type, value reflect.Value) error {
	// Convert reflect.Value to concrete type and delegate to typed method
	var v *ValidationDemo
	if value.Kind() == reflect.Ptr {
		if value.IsNil() {
			// For pointer types, allocate using type_.Elem()
			value.Set(reflect.New(type_.Elem()))
		}
		v = value.Interface().(*ValidationDemo)
	} else {
		// value must be addressable for read
		v = value.Addr().Interface().(*ValidationDemo)
	}
	// Delegate to strongly-typed method for maximum performance
	return g.ReadTyped(ctx, v)
}

// Compile-time guards: These ensure struct definitions haven't changed
// since code generation. If you modify structs, re-run go generate.

// Snapshot of DynamicSliceDemo's underlying type at generation time.
type _DynamicSliceDemo_expected struct {
	DynamicSlice []interface{}
}

// Compile-time check: this conversion is legal only if DynamicSliceDemo's underlying type
// is identical to _DynamicSliceDemo_expected (names, order, types, tags).
//
// If compilation fails here, it means you've modified the DynamicSliceDemo struct but haven't
// regenerated the code. Please run: go generate
//
// If go generate also fails, delete this file first: rm dynamicslicedemo_fory_gen.go
// Then run: go generate
var _ = func(x DynamicSliceDemo) {
	// ERROR: DynamicSliceDemo struct has changed! Run 'go generate' to fix this.
	_ = _DynamicSliceDemo_expected(x)
}

// Snapshot of MapDemo's underlying type at generation time.
type _MapDemo_expected struct {
	StringMap map[string]string
	IntMap    map[int]int
	MixedMap  map[string]int
}

// Compile-time check: this conversion is legal only if MapDemo's underlying type
// is identical to _MapDemo_expected (names, order, types, tags).
//
// If compilation fails here, it means you've modified the MapDemo struct but haven't
// regenerated the code. Please run: go generate
//
// If go generate also fails, delete this file first: rm mapdemo_fory_gen.go
// Then run: go generate
var _ = func(x MapDemo) {
	// ERROR: MapDemo struct has changed! Run 'go generate' to fix this.
	_ = _MapDemo_expected(x)
}

// Snapshot of SliceDemo's underlying type at generation time.
type _SliceDemo_expected struct {
	IntSlice    []int32
	StringSlice []string
	FloatSlice  []float64
	BoolSlice   []bool
}

// Compile-time check: this conversion is legal only if SliceDemo's underlying type
// is identical to _SliceDemo_expected (names, order, types, tags).
//
// If compilation fails here, it means you've modified the SliceDemo struct but haven't
// regenerated the code. Please run: go generate
//
// If go generate also fails, delete this file first: rm slicedemo_fory_gen.go
// Then run: go generate
var _ = func(x SliceDemo) {
	// ERROR: SliceDemo struct has changed! Run 'go generate' to fix this.
	_ = _SliceDemo_expected(x)
}

// Snapshot of ValidationDemo's underlying type at generation time.
type _ValidationDemo_expected struct {
	A int32
	B string
	C int64
	D float64
	E bool
}

// Compile-time check: this conversion is legal only if ValidationDemo's underlying type
// is identical to _ValidationDemo_expected (names, order, types, tags).
//
// If compilation fails here, it means you've modified the ValidationDemo struct but haven't
// regenerated the code. Please run: go generate
//
// If go generate also fails, delete this file first: rm validationdemo_fory_gen.go
// Then run: go generate
var _ = func(x ValidationDemo) {
	// ERROR: ValidationDemo struct has changed! Run 'go generate' to fix this.
	_ = _ValidationDemo_expected(x)
}
